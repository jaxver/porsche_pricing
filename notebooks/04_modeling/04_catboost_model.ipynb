{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c096245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ML libraries\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from catboost import CatBoostRegressor, Pool, cv\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent.parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "from config import (\n",
    "    DATA_DIR_GOLD,\n",
    "    MODELS_DIR,\n",
    "    RESULTS_DIR,\n",
    "    MODEL_CATBOOST,\n",
    "    MODEL_CONFIG,\n",
    "    NUMERIC_FEATURES,\n",
    "    CATEGORICAL_FEATURES,\n",
    "    TARGET_VARIABLE\n",
    ")\n",
    "from elferspot_listings.utils.helpers import setup_logging, load_data, ensure_dir\n",
    "\n",
    "# Setup logging\n",
    "logger = setup_logging(level='INFO')\n",
    "logger.info(\"CatBoost modeling initialized\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_SEED = MODEL_CONFIG['random_state']\n",
    "np.random.seed(RANDOM_SEED)\n",
    "RESULTS_MODEL_DIR = ensure_dir(RESULTS_DIR / \"model_predictions\")\n",
    "RUN_ID = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4112732",
   "metadata": {},
   "source": [
    "## Step 1: Load Gold Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5724aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the most recent gold file\n",
    "gold_files = sorted(DATA_DIR_GOLD.glob(\"listings_gold*.xlsx\"))\n",
    "\n",
    "if gold_files:\n",
    "    gold_path = gold_files[-1]\n",
    "    logger.info(f\"Using gold file: {gold_path.name}\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"No gold files found in {DATA_DIR_GOLD}\")\n",
    "\n",
    "# Load data\n",
    "df_gold = load_data(gold_path)\n",
    "print(f\"✓ Loaded {len(df_gold):,} rows from gold layer\")\n",
    "print(f\"  File: {gold_path.name}\")\n",
    "\n",
    "df_gold.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05d866d",
   "metadata": {},
   "source": [
    "## Step 2: Define Features for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae69afd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [col for col in NUMERIC_FEATURES if col in df_gold.columns]\n",
    "categorical_features = [col for col in CATEGORICAL_FEATURES if col in df_gold.columns]\n",
    "all_features = numeric_features + categorical_features\n",
    "target_column = 'log_price' if 'log_price' in df_gold.columns else TARGET_VARIABLE\n",
    "\n",
    "if not all_features:\n",
    "    raise ValueError(\"No modeling features were found in the Gold dataset. Verify feature engineering output.\")\n",
    "\n",
    "print(f\"Numeric features ({len(numeric_features)}): {numeric_features}\")\n",
    "print(f\"\\nCategorical features ({len(categorical_features)}): {categorical_features}\")\n",
    "print(f\"\\nTarget column: {target_column}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd48834",
   "metadata": {},
   "source": [
    "## Step 3: Prepare Modeling Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594afe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "required_columns = all_features + [target_column, TARGET_VARIABLE]\n",
    "missing_columns = [col for col in required_columns if col not in df_gold.columns]\n",
    "if missing_columns:\n",
    "    raise ValueError(f\"Missing required columns in Gold dataset: {missing_columns}\")\n",
    "\n",
    "df_model = df_gold[required_columns].copy()\n",
    "df_model = df_model.dropna(subset=[target_column, TARGET_VARIABLE])\n",
    "\n",
    "for col in categorical_features:\n",
    "    df_model[col] = df_model[col].fillna('Unknown').astype(str)\n",
    "\n",
    "for col in numeric_features:\n",
    "    df_model[col] = pd.to_numeric(df_model[col], errors='coerce')\n",
    "    df_model[col] = df_model[col].fillna(df_model[col].median())\n",
    "\n",
    "print(f\"Dataset ready with shape: {df_model.shape}\")\n",
    "print(f\"Remaining nulls:\\n{df_model.isnull().sum()[df_model.isnull().sum() > 0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7620c9",
   "metadata": {},
   "source": [
    "## Step 4: Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d74765",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_model[all_features]\n",
    "y = df_model[target_column]\n",
    "price_series = df_model[TARGET_VARIABLE]\n",
    "\n",
    "X_train, X_test, y_train, y_test, price_train, price_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    price_series,\n",
    "    test_size=MODEL_CONFIG['test_size'],\n",
    "    random_state=RANDOM_SEED\n",
    " )\n",
    "\n",
    "print(f\"Training set: {len(X_train):,} samples\")\n",
    "print(f\"Test set: {len(X_test):,} samples\")\n",
    "print(f\"Split ratio: {MODEL_CONFIG['test_size']*100:.0f}% test\")\n",
    "\n",
    "cat_feature_indices = [X_train.columns.get_loc(col) for col in categorical_features if col in X_train.columns]\n",
    "print(f\"\\nCategorical feature indices: {len(cat_feature_indices)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dc51ad",
   "metadata": {},
   "source": [
    "## Step 5: Train CatBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e09599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CatBoost model with config\n",
    "model = CatBoostRegressor(\n",
    "    iterations=MODEL_CONFIG['catboost']['iterations'],\n",
    "    learning_rate=MODEL_CONFIG['catboost']['learning_rate'],\n",
    "    depth=MODEL_CONFIG['catboost']['depth'],\n",
    "    l2_leaf_reg=MODEL_CONFIG['catboost']['l2_leaf_reg'],\n",
    "    random_seed=MODEL_CONFIG['catboost']['random_seed'],\n",
    "    cat_features=cat_feature_indices,\n",
    "    verbose=100,\n",
    "    eval_metric='RMSE',\n",
    "    early_stopping_rounds=50\n",
    ")\n",
    "\n",
    "print(\"Training CatBoost model...\")\n",
    "print(f\"Configuration: {MODEL_CONFIG['catboost']}\")\n",
    "\n",
    "# Train model\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=(X_test, y_test),\n",
    "    plot=False\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Model training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b92478a",
   "metadata": {},
   "source": [
    "## Step 6: Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9110df",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "if target_column == TARGET_VARIABLE:\n",
    "    y_train_price = y_train\n",
    "    y_test_price = y_test\n",
    "    y_train_pred_price = y_train_pred\n",
    "    y_test_pred_price = y_test_pred\n",
    "    y_train_log = np.log(np.maximum(y_train_price, 1))\n",
    "    y_test_log = np.log(np.maximum(y_test_price, 1))\n",
    "    y_train_pred_log = np.log(np.maximum(y_train_pred_price, 1))\n",
    "    y_test_pred_log = np.log(np.maximum(y_test_pred_price, 1))\n",
    "else:\n",
    "    y_train_price = price_train\n",
    "    y_test_price = price_test\n",
    "    y_train_pred_price = np.exp(y_train_pred)\n",
    "    y_test_pred_price = np.exp(y_test_pred)\n",
    "    y_train_log = y_train\n",
    "    y_test_log = y_test\n",
    "    y_train_pred_log = y_train_pred\n",
    "    y_test_pred_log = y_test_pred\n",
    "\n",
    "def summarize_metrics(y_true, y_pred, label: str) -> dict:\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"\\n{label} Metrics:\")\n",
    "    print(f\"  RMSE: {rmse:,.4f}\")\n",
    "    print(f\"  MAE:  {mae:,.4f}\")\n",
    "    print(f\"  R²:   {r2:.4f}\")\n",
    "    return {'RMSE': rmse, 'MAE': mae, 'R2': r2}\n",
    "\n",
    "train_metrics_log = summarize_metrics(y_train_log, y_train_pred_log, 'Training (log)')\n",
    "test_metrics_log = summarize_metrics(y_test_log, y_test_pred_log, 'Test (log)')\n",
    "\n",
    "train_metrics_price = summarize_metrics(y_train_price, y_train_pred_price, 'Training (price)')\n",
    "test_metrics_price = summarize_metrics(y_test_price, y_test_pred_price, 'Test (price)')\n",
    "\n",
    "print(\"\\nOverfitting check (price scale):\")\n",
    "print(f\"  R² gap: {train_metrics_price['R2'] - test_metrics_price['R2']:.4f}\")\n",
    "if train_metrics_price['R2'] - test_metrics_price['R2'] > 0.1:\n",
    "    print(\"  ⚠️ Potential overfitting\")\n",
    "else:\n",
    "    print(\"  ✓ Generalization looks healthy\")\n",
    "\n",
    "residuals_price = y_test_price - y_test_pred_price\n",
    "residuals_log = y_test_log - y_test_pred_log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8092beed",
   "metadata": {},
   "source": [
    "## Step 7: Prediction Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae5eb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].scatter(y_test_price, y_test_pred_price, alpha=0.5)\n",
    "axes[0].plot([y_test_price.min(), y_test_price.max()], [y_test_price.min(), y_test_price.max()], 'r--', lw=2)\n",
    "axes[0].set_xlabel('Actual Price (EUR)')\n",
    "axes[0].set_ylabel('Predicted Price (EUR)')\n",
    "axes[0].set_title(f'Predicted vs Actual (Test)\\nR² = {test_metrics_price[\"R2\"]:.4f}')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].scatter(y_test_pred_price, residuals_price, alpha=0.5)\n",
    "axes[1].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "axes[1].set_xlabel('Predicted Price (EUR)')\n",
    "axes[1].set_ylabel('Residuals (EUR)')\n",
    "axes[1].set_title('Residual Plot')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nResidual Statistics (price scale):\")\n",
    "print(f\"  Mean: {residuals_price.mean():.2f}\")\n",
    "print(f\"  Std:  {residuals_price.std():.2f}\")\n",
    "print(f\"  Min:  {residuals_price.min():.2f}\")\n",
    "print(f\"  Max:  {residuals_price.max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e135a32f",
   "metadata": {},
   "source": [
    "## Step 8: Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47235e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"=== Top 20 Most Important Features ===\")\n",
    "display(feature_importance.head(20))\n",
    "\n",
    "# Visualize feature importance\n",
    "plt.figure(figsize=(10, 8))\n",
    "top_features = feature_importance.head(20)\n",
    "plt.barh(range(len(top_features)), top_features['importance'])\n",
    "plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Top 20 Feature Importances')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1933684",
   "metadata": {},
   "source": [
    "## Step 9: Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc5c625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross-validation\n",
    "print(\"Performing 5-fold cross-validation...\")\n",
    "\n",
    "# Create Pool for CatBoost CV\n",
    "cv_data = Pool(\n",
    "    data=X_train,\n",
    "    label=y_train,\n",
    "    cat_features=cat_feature_indices\n",
    ")\n",
    "\n",
    "# CV parameters\n",
    "cv_params = {\n",
    "    'iterations': 500,\n",
    "    'learning_rate': MODEL_CONFIG['catboost']['learning_rate'],\n",
    "    'depth': MODEL_CONFIG['catboost']['depth'],\n",
    "    'l2_leaf_reg': MODEL_CONFIG['catboost']['l2_leaf_reg'],\n",
    "    'random_seed': RANDOM_SEED,\n",
    "    'verbose': False\n",
    "}\n",
    "\n",
    "# Run CV\n",
    "cv_results = cv(\n",
    "    cv_data,\n",
    "    cv_params,\n",
    "    fold_count=5,\n",
    "    shuffle=True,\n",
    "    partition_random_seed=RANDOM_SEED,\n",
    "    plot=False,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Display CV results\n",
    "print(f\"\\nCross-Validation Results:\")\n",
    "print(f\"  Mean RMSE: {cv_results['test-RMSE-mean'].iloc[-1]:.4f}\")\n",
    "print(f\"  Std RMSE:  {cv_results['test-RMSE-std'].iloc[-1]:.4f}\")\n",
    "\n",
    "# Plot CV learning curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(cv_results['test-RMSE-mean'], label='CV Mean RMSE')\n",
    "plt.fill_between(\n",
    "    range(len(cv_results)),\n",
    "    cv_results['test-RMSE-mean'] - cv_results['test-RMSE-std'],\n",
    "    cv_results['test-RMSE-mean'] + cv_results['test-RMSE-std'],\n",
    "    alpha=0.3\n",
    ")\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Cross-Validation Learning Curve')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2195b60a",
   "metadata": {},
   "source": [
    "## Persist predictions\n",
    "Store model-level prediction intervals for downstream analysis notebooks (price opportunity scans, KPI reporting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e25844",
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_z = 1.645\n",
    "residual_std_log = residuals_log.std(ddof=1)\n",
    "pred_lower = np.exp(y_test_pred_log - ci_z * residual_std_log)\n",
    "pred_upper = np.exp(y_test_pred_log + ci_z * residual_std_log)\n",
    "\n",
    "base_cols = [\n",
    "    'URL',\n",
    "    'Title',\n",
    "    'Model',\n",
    "    'Series',\n",
    "    'Year of construction',\n",
    "    'Mileage_km',\n",
    "    'price_in_eur',\n",
    "    'Car location',\n",
    "]\n",
    "available_cols = [col for col in base_cols if col in df_gold.columns]\n",
    "results_df = df_gold.loc[X_test.index, available_cols].copy()\n",
    "results_df['pred_price'] = y_test_pred_price\n",
    "results_df['pred_lower'] = pred_lower\n",
    "results_df['pred_upper'] = pred_upper\n",
    "results_df['residual_price'] = residuals_price\n",
    "results_df['residual_log'] = residuals_log\n",
    "results_df['model'] = 'catboost'\n",
    "results_df['run_id'] = RUN_ID\n",
    "\n",
    "underpriced_df = results_df[results_df['price_in_eur'] < results_df['pred_lower']].copy()\n",
    "overpriced_df = results_df[results_df['price_in_eur'] > results_df['pred_upper']].copy()\n",
    "\n",
    "prediction_file = RESULTS_MODEL_DIR / f\"catboost_predictions_{RUN_ID}.xlsx\"\n",
    "with pd.ExcelWriter(prediction_file) as writer:\n",
    "    results_df.sort_values('residual_price').to_excel(writer, sheet_name='all_results', index=False)\n",
    "    underpriced_df.sort_values('residual_price').to_excel(writer, sheet_name='underpriced', index=False)\n",
    "    overpriced_df.sort_values('residual_price').to_excel(writer, sheet_name='overpriced', index=False)\n",
    "\n",
    "print(f\"✓ Prediction export saved to {prediction_file}\")\n",
    "print(f\"  Underpriced listings: {len(underpriced_df)}\")\n",
    "print(f\"  Overpriced listings: {len(overpriced_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4309c159",
   "metadata": {},
   "source": [
    "## Step 10: Save Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7200f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "model_path = MODELS_DIR / f\"catboost_model_{RUN_ID}.cbm\"\n",
    "model.save_model(str(model_path))\n",
    "\n",
    "importance_path = MODELS_DIR / f\"feature_importance_{RUN_ID}.csv\"\n",
    "feature_importance.to_csv(importance_path, index=False)\n",
    "\n",
    "metrics_df = pd.DataFrame({\n",
    "    'metric': ['RMSE', 'MAE', 'R2'],\n",
    "    'train': [train_metrics_price['RMSE'], train_metrics_price['MAE'], train_metrics_price['R2']],\n",
    "    'test': [test_metrics_price['RMSE'], test_metrics_price['MAE'], test_metrics_price['R2']]\n",
    "})\n",
    "metrics_path = MODELS_DIR / f\"model_metrics_{RUN_ID}.csv\"\n",
    "metrics_df.to_csv(metrics_path, index=False)\n",
    "\n",
    "print(f\"✓ Model saved to: {model_path}\")\n",
    "print(f\"✓ Feature importance saved to: {importance_path}\")\n",
    "print(f\"✓ Metrics saved to: {metrics_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94e08a6",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "✓ **CatBoost Model Training Complete**\n",
    "\n",
    "### Model Performance\n",
    "- **Test R²:** {test_metrics_price['R2']:.4f}\n",
    "- **Test RMSE:** {test_metrics_price['RMSE']:,.2f} EUR\n",
    "- **Test MAE:** {test_metrics_price['MAE']:,.2f} EUR\n",
    "\n",
    "### Files Saved\n",
    "- Model: `{model_path.name}`\n",
    "- Feature Importance: `{importance_path.name}`\n",
    "- Metrics: `{metrics_path.name}`\n",
    "- Predictions: `{prediction_file.name}`\n",
    "\n",
    "**Next Steps:**\n",
    "- Compare with other models (Ridge, ElasticNet)\n",
    "- Feed `model_predictions/catboost_predictions_*.xlsx` into analysis notebooks\n",
    "- Deploy model in Streamlit app"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
